{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aabf56d",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48ecd411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0609af7f",
   "metadata": {},
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30c99524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open(\"AllData.pkl\",\"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d178fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformating into training and validation data\n",
    "\n",
    "train_airfoils = [6, 13, 21, 25]\n",
    "validation_airfoils = [9]\n",
    "\n",
    "\n",
    "def process_data(airfoils):\n",
    "    x = []\n",
    "    x_phys_ext = []\n",
    "    x_phys = []\n",
    "    y = []\n",
    "    for airfoil in airfoils:\n",
    "        for i in range(len(data[airfoil][\"alpha\"])):\n",
    "            x.append(np.reshape(data[airfoil][\"coords_reduced\"],-1))\n",
    "            x_phys_ext.append([data[airfoil][\"alpha\"][i],data[airfoil][\"Cl_approx_exp\"][i],data[airfoil][\"Cd_approx_exp\"][i]])\n",
    "            x_phys.append([data[airfoil][\"alpha\"][i],data[airfoil][\"Cl_approx\"][i],data[airfoil][\"Cd_approx\"][i]])\n",
    "            y.append([data[airfoil][\"Cl_target\"][i], data[airfoil][\"Cd_target\"][i]])\n",
    "    x = np.array(x )\n",
    "    x_phys_ext = np.array(x_phys_ext)\n",
    "    x_phys = np.array(x_phys)\n",
    "    y = np.array(y)\n",
    "    return x, x_phys_ext, x_phys, y\n",
    "\n",
    "\n",
    "x_train, x_train_phys_ext, x_train_phys, y_train = process_data(train_airfoils)\n",
    "x_val, x_val_phys_ext, x_val_phys, y_val = process_data(validation_airfoils)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a00285",
   "metadata": {},
   "source": [
    "# DNN and PGNN training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "456a4672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for trtaining single nn\n",
    "def train_nn(mode,\n",
    "            x_train,\n",
    "            x_train_phys,\n",
    "            y_train,\n",
    "            x_val,\n",
    "            x_val_phys,\n",
    "            y_val,\n",
    "             verbose\n",
    "            ):\n",
    "    # build NN\n",
    "    inputs = tf.keras.layers.Input(40,)\n",
    "    if \"PGNN\" in mode:\n",
    "        phys = tf.keras.layers.Input(3,)\n",
    "        inputs2 = inputs\n",
    "    elif mode == \"DDNN\":\n",
    "        phys = tf.keras.layers.Input(1,)\n",
    "        inputs2 = tf.keras.layers.Concatenate()([inputs,phys])\n",
    "        \n",
    "    hidden_nodes = 20\n",
    "    \n",
    "    \n",
    "    if mode == \"PGNN_1\":\n",
    "        merged = tf.keras.layers.Concatenate()([inputs2,phys])\n",
    "        h1 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(merged)\n",
    "    else:\n",
    "        h1 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(inputs2)\n",
    "    \n",
    "    if mode == \"PGNN_2\":\n",
    "        merged = tf.keras.layers.Concatenate()([h1,phys])\n",
    "        h2 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(merged)\n",
    "    else:\n",
    "        h2 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(h1)\n",
    "    \n",
    "    if mode == \"PGNN_3\":\n",
    "        merged = tf.keras.layers.Concatenate()([h2,phys])\n",
    "        h3 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(merged)\n",
    "    else:\n",
    "        h3 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(h2)\n",
    "        \n",
    "        \n",
    "    if mode == \"PGNN_4\":\n",
    "        merged = tf.keras.layers.Concatenate()([h3,phys])\n",
    "        h4 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(merged)\n",
    "    else:\n",
    "        h4 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(h3)\n",
    "        \n",
    "    if mode == \"PGNN_5\":\n",
    "        merged = tf.keras.layers.Concatenate()([h4,phys])\n",
    "        h5 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(merged)\n",
    "    else:\n",
    "        h5 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(h4)    \n",
    "    \n",
    "    if mode == \"PGNN_6\":\n",
    "        merged = tf.keras.layers.Concatenate()([h5,phys])\n",
    "        h6 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(merged)\n",
    "    else:\n",
    "        h6 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(h5)  \n",
    "        \n",
    "    outputs = tf.keras.layers.Dense(2, activation=None, \n",
    "                               kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                               bias_initializer=tf.keras.initializers.Zeros()\n",
    "                              )(h6)\n",
    "    model = tf.keras.Model(inputs=[inputs,phys],outputs = outputs)\n",
    "   \n",
    "    # compiel NN\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "        loss = \"mse\",\n",
    "    )\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    history = model.fit(\n",
    "        x = [x_train,x_train_phys],\n",
    "        y = y_train,\n",
    "        batch_size = 64,\n",
    "        epochs = 200,\n",
    "        callbacks = [\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor=\"val_loss\",\n",
    "                    min_delta=0,\n",
    "                    patience=8,\n",
    "                    verbose=0,\n",
    "                    restore_best_weights=True,\n",
    "                    start_from_epoch=0,\n",
    "                    ),\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    monitor=\"val_loss\",\n",
    "                    factor=0.1,\n",
    "                    patience=3,\n",
    "                    min_delta=0,\n",
    "                    )\n",
    "                ],\n",
    "        validation_data = ([x_val, x_val_phys],y_val),\n",
    "            verbose = verbose\n",
    "        )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0b82670",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_ensemble(\n",
    "            nns, \n",
    "            mode, \n",
    "            x_train,\n",
    "            x_train_phys,\n",
    "            y_train,\n",
    "            x_val,\n",
    "            x_val_phys,\n",
    "            y_val,\n",
    "            verbose = 1\n",
    "            ):\n",
    "    models, histories = [], []\n",
    "    for i in range(nns):\n",
    "        model, history = train_nn(mode, x_train,x_train_phys, y_train,x_val,x_val_phys,y_val,verbose-1)\n",
    "        models.append(model)\n",
    "        histories.append(history)\n",
    "        if verbose>0:\n",
    "            print(\"NN \",i, \n",
    "                  \", Epochs\",len(history.history[\"loss\"]), \n",
    "                  \", loss\", history.history[\"loss\"][-1], \n",
    "                  \", val_loss\", history.history[\"val_loss\"][-1])\n",
    "    \n",
    "    return models, histories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5968f311",
   "metadata": {},
   "source": [
    "# Train neural network ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f5c790f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN  0 , Epochs 45 , loss 0.004756356589496136 , val_loss 0.004695691633969545\n",
      "NN  1 , Epochs 46 , loss 0.007959380745887756 , val_loss 0.008454222232103348\n",
      "NN  2 , Epochs 45 , loss 0.005305887665599585 , val_loss 0.005581320729106665\n",
      "NN  3 , Epochs 59 , loss 0.004665972664952278 , val_loss 0.0048824152909219265\n",
      "NN  4 , Epochs 52 , loss 0.007411001715809107 , val_loss 0.00684585515409708\n",
      "NN  5 , Epochs 36 , loss 0.00492939492687583 , val_loss 0.005622609052807093\n",
      "NN  6 , Epochs 44 , loss 0.006691266782581806 , val_loss 0.006732292007654905\n",
      "NN  7 , Epochs 32 , loss 0.006459773983806372 , val_loss 0.006929614115506411\n",
      "NN  8 , Epochs 52 , loss 0.005141319241374731 , val_loss 0.005442237481474876\n",
      "NN  9 , Epochs 39 , loss 0.0051480857655406 , val_loss 0.005615919828414917\n",
      "NN  0 , Epochs 58 , loss 0.014844915829598904 , val_loss 0.015441753901541233\n",
      "NN  1 , Epochs 49 , loss 0.04981771111488342 , val_loss 0.054547689855098724\n",
      "NN  2 , Epochs 52 , loss 0.014415880665183067 , val_loss 0.015771569684147835\n",
      "NN  3 , Epochs 54 , loss 0.007413855288177729 , val_loss 0.012122423388063908\n",
      "NN  4 , Epochs 85 , loss 0.025849007070064545 , val_loss 0.027204707264900208\n",
      "NN  5 , Epochs 39 , loss 0.1265043318271637 , val_loss 0.11781780421733856\n",
      "NN  6 , Epochs 42 , loss 0.01593344658613205 , val_loss 0.017394987866282463\n",
      "NN  7 , Epochs 53 , loss 0.053291093558073044 , val_loss 0.05205591022968292\n",
      "NN  8 , Epochs 89 , loss 0.019270002841949463 , val_loss 0.023253992199897766\n",
      "NN  9 , Epochs 93 , loss 0.03280444070696831 , val_loss 0.038287267088890076\n"
     ]
    }
   ],
   "source": [
    "# build ensemble\n",
    "\n",
    "nns = 10\n",
    "\n",
    "models_PGNN, hists = build_ensemble(\n",
    "                nns, \n",
    "                mode = \"PGNN_4\", \n",
    "                x_train=x_train,\n",
    "                x_train_phys=x_train_phys_ext,\n",
    "                y_train=y_train,\n",
    "                x_val=x_val,\n",
    "                x_val_phys = x_val_phys_ext,\n",
    "                y_val = y_val,\n",
    "                verbose = 1\n",
    "    )\n",
    "\n",
    "models_DDNN, hists = build_ensemble(\n",
    "                nns, \n",
    "                mode = \"DDNN\", \n",
    "                x_train=x_train,\n",
    "                x_train_phys=x_train_phys[:,0],\n",
    "                y_train=y_train,\n",
    "                x_val=x_val,\n",
    "                x_val_phys = x_val_phys_ext[:,0],\n",
    "                y_val = y_val,\n",
    "                verbose = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbe825f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec7b0866ccb4241b03bbe660a711cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test on each airfoil\n",
    "\n",
    "\n",
    "def MSE(x,y):\n",
    "    x = np.reshape(np.array(x),-1)\n",
    "    y = np.reshape(np.array(y),-1)\n",
    "    z = np.mean((x-y)**2)\n",
    "    return z\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "mse_pgnn=[]\n",
    "mse_ddnn=[]\n",
    "mse_combined=[]\n",
    "mse_0 = []\n",
    "mse_05=[]\n",
    "for airfoil in tqdm(range(0,30)):\n",
    "    \n",
    "    x_test, x_test_phys_ext, x_test_phys, y_test = process_data([airfoil])\n",
    "    \n",
    "    mean = []\n",
    "    for model in models_PGNN:\n",
    "        y_pred = model.predict( \n",
    "            x = [x_test,x_test_phys_ext],verbose=0\n",
    "        )\n",
    "        mean.append(y_pred)\n",
    "\n",
    "    mean_pgnn = np.array(mean).mean(axis=0)\n",
    "    mse_pgnn.append(MSE(mean_pgnn,y_test))\n",
    "    \n",
    "    mean = []\n",
    "    for model in models_DDNN:\n",
    "        y_pred = model.predict( \n",
    "            x = [x_test,x_test_phys[:,0]],verbose=0\n",
    "        )\n",
    "        mean.append(y_pred)\n",
    "\n",
    "    mean_ddnn = np.array(mean).mean(axis=0)\n",
    "    mse_ddnn.append(MSE(mean_ddnn,y_test))\n",
    "    \n",
    "    mse_0.append(MSE(np.zeros(y_test.shape),y_test))\n",
    "    \n",
    "    mse_05.append(MSE(np.reshape(np.concatenate([np.zeros(y_test.shape[0]),\n",
    "                                               np.zeros(y_test.shape[0], dtype=float)+0.5]),y_test.shape),y_test))\n",
    "    \n",
    "    #if airfoil < 2:\n",
    "        \n",
    "    if airfoil <6:\n",
    "        mse_combined.append(MSE(mean_ddnn,y_test))\n",
    "    else:\n",
    "        mse_combined.append(MSE(mean_pgnn,y_test))\n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83ec014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = {\n",
    "    \"mse_ddnn\":mse_ddnn,\n",
    "    \"mse_pgnn\":mse_pgnn,\n",
    "    \"mse_combined\":mse_combined\n",
    "}\n",
    "\n",
    "with open(\"full_blade.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mse,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c77c15",
   "metadata": {},
   "source": [
    "# Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2d4223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"full_blade.pkl\", \"rb\") as f:\n",
    "    mse = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17a3a23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df0c622041b45e5af195950a621158e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "font = {\n",
    "        'size'   : 16}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(mse_ddnn, label = \"DDNN\")\n",
    "plt.plot(mse_pgnn, label = \"PGNN\")\n",
    "plt.plot(mse_combined, label=\"Combined\", linestyle= \":\", color=\"black\")\n",
    "#plt.plot(mse_0, label = \"No lift and drag\")\n",
    "#plt.plot(mse_05, label = \"No lift and 0.5 drag\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Mean squared error\")\n",
    "plt.xlabel(\"Airfoil\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"full_blade.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8777e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f7dd7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ec1f4bbb4041868c952b3fc6858aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20071706700>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternative plotting style\n",
    "\n",
    "fig,(ax,ax2) = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "\n",
    "ax2.plot(mse_pgnn, label = \"PGNN\")\n",
    "ax2.plot(mse_ddnn, label = \"DDNN\")\n",
    "ax2.plot(mse_combined, label=\"Combined\", linestyle= \":\", color=\"black\")\n",
    "\n",
    "ax.plot(mse_pgnn, label = \"PGNN\")\n",
    "\n",
    "ax2.set_yscale(\"log\")\n",
    "ax2.set_ylim(1e-3, 2e0)\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylim(1.5e1, 1e4)\n",
    "\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1343f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
