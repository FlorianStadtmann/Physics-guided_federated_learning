{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "852f49c0",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b01f187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d68d430",
   "metadata": {},
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc559ee4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'AllData.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21152/2324253686.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"AllData.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AllData.pkl'"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "with open(\"AllData.pkl\",\"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5de0210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and validation set\n",
    "\n",
    "train_airfoils = [5, 13, 21, 25]\n",
    "validation_airfoils = [9]\n",
    "test_airfoils = [17]\n",
    "# dataset shapes:\n",
    "# x_train [samples, [x_coords,y_coords]]\n",
    "# x_train_phys [samples, alpha & cl_approx_exp & cl_approx_exp ]\n",
    "# y_train [samples, cl & cd]\n",
    "\n",
    "\n",
    "def process_data(airfoils):\n",
    "    x = []\n",
    "    x_phys_ext = []\n",
    "    x_phys = []\n",
    "    y = []\n",
    "    for airfoil in airfoils:\n",
    "        for i in range(len(data[airfoil][\"alpha\"])):\n",
    "            x.append(np.reshape(data[airfoil][\"coords_reduced\"],-1))\n",
    "            x_phys_ext.append([data[airfoil][\"alpha\"][i],data[airfoil][\"Cl_approx_exp\"][i],data[airfoil][\"Cd_approx_exp\"][i]])\n",
    "            x_phys.append([data[airfoil][\"alpha\"][i],data[airfoil][\"Cl_approx\"][i],data[airfoil][\"Cd_approx\"][i]])\n",
    "            y.append([data[airfoil][\"Cl_target\"][i], data[airfoil][\"Cd_target\"][i]])\n",
    "    x = np.array(x )\n",
    "    x_phys_ext = np.array(x_phys_ext)\n",
    "    x_phys = np.array(x_phys)\n",
    "    y = np.array(y)\n",
    "    return x, x_phys_ext, x_phys, y\n",
    "    \n",
    "    \n",
    "x_train, x_train_phys_ext, x_train_phys, y_train = process_data(train_airfoils)\n",
    "x_val, x_val_phys_ext, x_val_phys, y_val = process_data(validation_airfoils)\n",
    "x_test, x_test_phys_ext, x_test_phys, y_test = process_data(test_airfoils)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d11ab",
   "metadata": {},
   "source": [
    "# Define functions for DNN and PGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "190a04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for trtaining single nn\n",
    "def train_nn(mode,\n",
    "            x_train,\n",
    "            x_train_phys,\n",
    "            y_train,\n",
    "            x_val,\n",
    "            x_val_phys,\n",
    "            y_val,\n",
    "             verbose\n",
    "            ):\n",
    "    # build NN\n",
    "    inputs = tf.keras.layers.Input(40,)\n",
    "    if \"PGNN\" in mode:\n",
    "        phys = tf.keras.layers.Input(3,)\n",
    "        inputs2 = inputs\n",
    "    elif mode == \"DDNN\":\n",
    "        phys = tf.keras.layers.Input(1,)\n",
    "        inputs2 = tf.keras.layers.Concatenate()([inputs,phys])\n",
    "        \n",
    "    hidden_nodes = 20\n",
    "    \n",
    "    \n",
    "    if mode == \"PGNN_1\":\n",
    "        merged = tf.keras.layers.Concatenate()([inputs2,phys])\n",
    "        h1 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(merged)\n",
    "    else:\n",
    "        h1 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(inputs2)\n",
    "    \n",
    "    if mode == \"PGNN_2\":\n",
    "        merged = tf.keras.layers.Concatenate()([h1,phys])\n",
    "        h2 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(merged)\n",
    "    else:\n",
    "        h2 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(h1)\n",
    "    \n",
    "    if mode == \"PGNN_3\":\n",
    "        merged = tf.keras.layers.Concatenate()([h2,phys])\n",
    "        h3 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(merged)\n",
    "    else:\n",
    "        h3 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(h2)\n",
    "        \n",
    "        \n",
    "    if mode == \"PGNN_4\":\n",
    "        merged = tf.keras.layers.Concatenate()([h3,phys])\n",
    "        h4 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(merged)\n",
    "    else:\n",
    "        h4 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(h3)\n",
    "        \n",
    "    if mode == \"PGNN_5\":\n",
    "        merged = tf.keras.layers.Concatenate()([h4,phys])\n",
    "        h5 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(merged)\n",
    "    else:\n",
    "        h5 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(h4)    \n",
    "    \n",
    "    if mode == \"PGNN_6\":\n",
    "        merged = tf.keras.layers.Concatenate()([h5,phys])\n",
    "        h6 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(merged)\n",
    "    else:\n",
    "        h6 = tf.keras.layers.Dense(hidden_nodes, activation=tf.nn.relu, \n",
    "                                   kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                                   bias_initializer=tf.keras.initializers.Zeros()\n",
    "                                  )(h5)  \n",
    "        \n",
    "    outputs = tf.keras.layers.Dense(2, activation=None, \n",
    "                               kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                               bias_initializer=tf.keras.initializers.Zeros()\n",
    "                              )(h6)\n",
    "    model = tf.keras.Model(inputs=[inputs,phys],outputs = outputs)\n",
    "   \n",
    "    # compiel NN\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "        loss = \"mse\",\n",
    "    )\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    history = model.fit(\n",
    "        x = [x_train,x_train_phys],\n",
    "        y = y_train,\n",
    "        batch_size = 64,\n",
    "        epochs = 200,\n",
    "        callbacks = [\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor=\"val_loss\",\n",
    "                    min_delta=0,\n",
    "                    patience=8,\n",
    "                    verbose=0,\n",
    "                    restore_best_weights=True,\n",
    "                    start_from_epoch=0,\n",
    "                    ),\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    monitor=\"val_loss\",\n",
    "                    factor=0.1,\n",
    "                    patience=3,\n",
    "                    min_delta=0,\n",
    "                    )\n",
    "                ],\n",
    "        validation_data = ([x_val, x_val_phys],y_val),\n",
    "            verbose = verbose\n",
    "        )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "18c39eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for creating an ensemble\n",
    "\n",
    "def build_ensemble(\n",
    "            nns, \n",
    "            mode, \n",
    "            x_train,\n",
    "            x_train_phys,\n",
    "            y_train,\n",
    "            x_val,\n",
    "            x_val_phys,\n",
    "            y_val,\n",
    "            verbose = 1\n",
    "            ):\n",
    "    models, histories = [], []\n",
    "    for i in range(nns):\n",
    "        model, history = train_nn(mode, x_train,x_train_phys, y_train,x_val,x_val_phys,y_val,verbose-1)\n",
    "        models.append(model)\n",
    "        histories.append(history)\n",
    "        if verbose>0:\n",
    "            print(\"NN \",i, \n",
    "                  \", Epochs\",len(history.history[\"loss\"]), \n",
    "                  \", loss\", history.history[\"loss\"][-1], \n",
    "                  \", val_loss\", history.history[\"val_loss\"][-1])\n",
    "    \n",
    "    return models, histories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91f18b8",
   "metadata": {},
   "source": [
    "# Create Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1a0efd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN  0 , Epochs 9 , loss 0.5556554794311523 , val_loss 0.6682834029197693\n",
      "NN  1 , Epochs 44 , loss 0.02065730094909668 , val_loss 0.025566376745700836\n",
      "NN  2 , Epochs 78 , loss 0.013449029996991158 , val_loss 0.018490538001060486\n",
      "NN  3 , Epochs 118 , loss 0.026968831196427345 , val_loss 0.034359339624643326\n",
      "NN  4 , Epochs 46 , loss 0.0111951669678092 , val_loss 0.01874694414436817\n",
      "NN  5 , Epochs 47 , loss 0.019409343600273132 , val_loss 0.028651461005210876\n",
      "NN  6 , Epochs 15 , loss 0.2762572467327118 , val_loss 0.2985233664512634\n",
      "NN  7 , Epochs 54 , loss 0.013658598996698856 , val_loss 0.022636888548731804\n",
      "NN  8 , Epochs 189 , loss 0.05055311322212219 , val_loss 0.05028071999549866\n",
      "NN  9 , Epochs 43 , loss 0.016410792246460915 , val_loss 0.023076463490724564\n",
      "NN  0 , Epochs 41 , loss 0.010767693631350994 , val_loss 0.013793961144983768\n",
      "NN  1 , Epochs 32 , loss 0.014669984579086304 , val_loss 0.02002045139670372\n",
      "NN  2 , Epochs 34 , loss 0.0178357120603323 , val_loss 0.02214459888637066\n",
      "NN  3 , Epochs 50 , loss 0.018502406775951385 , val_loss 0.017990930005908012\n",
      "NN  4 , Epochs 39 , loss 0.014698993414640427 , val_loss 0.015196025371551514\n",
      "NN  5 , Epochs 33 , loss 0.01145545206964016 , val_loss 0.016680847853422165\n",
      "NN  6 , Epochs 69 , loss 0.02521301992237568 , val_loss 0.02136613056063652\n",
      "NN  7 , Epochs 51 , loss 0.00911754835397005 , val_loss 0.013029838912189007\n",
      "NN  8 , Epochs 83 , loss 0.02067267708480358 , val_loss 0.022782936692237854\n",
      "NN  9 , Epochs 64 , loss 0.017934028059244156 , val_loss 0.021764425560832024\n",
      "NN  0 , Epochs 77 , loss 0.0330219492316246 , val_loss 0.03890056535601616\n",
      "NN  1 , Epochs 54 , loss 0.1250227987766266 , val_loss 0.11942856013774872\n",
      "NN  2 , Epochs 68 , loss 0.02156759984791279 , val_loss 0.028767315670847893\n",
      "NN  3 , Epochs 52 , loss 0.015544715337455273 , val_loss 0.021847059950232506\n",
      "NN  4 , Epochs 39 , loss 0.01674787700176239 , val_loss 0.024705994874238968\n",
      "NN  5 , Epochs 53 , loss 0.03246338665485382 , val_loss 0.03861762955784798\n",
      "NN  6 , Epochs 77 , loss 0.050143349915742874 , val_loss 0.05177697166800499\n",
      "NN  7 , Epochs 52 , loss 0.018899613991379738 , val_loss 0.023855891078710556\n",
      "NN  8 , Epochs 56 , loss 0.008660961873829365 , val_loss 0.017019884660840034\n",
      "NN  9 , Epochs 61 , loss 0.22104662656784058 , val_loss 0.2408461719751358\n"
     ]
    }
   ],
   "source": [
    "nns = 10\n",
    "\n",
    "\n",
    "pgnns, pgnn_hists = build_ensemble(            \n",
    "            nns = nns,\n",
    "            mode = \"PGNN_3\", \n",
    "            x_train = x_train,\n",
    "            x_train_phys = x_train_phys,\n",
    "            y_train = y_train,\n",
    "            x_val = x_val,\n",
    "            x_val_phys = x_val_phys,\n",
    "            y_val = y_val,\n",
    "            verbose = 1)\n",
    "\n",
    "pgnns_exp, pgnn_exp_hists = build_ensemble(            \n",
    "            nns =nns,\n",
    "            mode = \"PGNN_4\", \n",
    "            x_train = x_train,\n",
    "            x_train_phys = x_train_phys_ext,\n",
    "            y_train = y_train,\n",
    "            x_val = x_val,\n",
    "            x_val_phys = x_val_phys_ext,\n",
    "            y_val = y_val,\n",
    "            verbose = 1)\n",
    "\n",
    "dnn, dnn_hists = build_ensemble(            \n",
    "            nns = nns,\n",
    "            mode = \"DDNN\", \n",
    "            x_train = x_train,\n",
    "            x_train_phys = x_train_phys[:,0],\n",
    "            y_train = y_train,\n",
    "            x_val = x_val,\n",
    "            x_val_phys = x_val_phys[:,0],\n",
    "            y_val = y_val,\n",
    "            verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "de48bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "\n",
    "def MSE(x,y):\n",
    "    x = np.reshape(np.array(x),-1)\n",
    "    y = np.reshape(np.array(y),-1)\n",
    "    z = np.mean((x-y)**2)\n",
    "    return z\n",
    "\n",
    "mean_pred=[]\n",
    "mse_5 = []\n",
    "for model in pgnns:\n",
    "    y_pred = model.predict( \n",
    "        x = [x_test,x_test_phys],verbose=0\n",
    "    )\n",
    "    #mse_5.append((MSE( y_pred[:50], y_test[:50]) + MSE(y_pred[150:], y_test[150:]))/2)\n",
    "    mse_5.append(MSE( y_pred, y_test))\n",
    "    mean_pred.append(y_pred)\n",
    "\n",
    "mean_pred_ext = []\n",
    "mse_ext_5=[]\n",
    "for model in pgnns_exp:\n",
    "    y_pred = model.predict( \n",
    "        x = [x_test,x_test_phys_ext],verbose=0\n",
    "    )\n",
    "    #mse_ext_5.append((MSE( y_pred[:50], y_test[:50]) + MSE(y_pred[150:], y_test[150:]))/2)\n",
    "    mse_ext_5.append(MSE( y_pred, y_test) )\n",
    "    mean_pred_ext.append(y_pred)\n",
    "\n",
    "mean_pred_dnn = []\n",
    "mse_dnn_5 = []\n",
    "for model in dnn:\n",
    "    y_pred = model.predict( \n",
    "        x = [x_test,x_test_phys[:,0]], verbose=0\n",
    "    )\n",
    "    #mse_dnn_5.append((MSE( y_pred[:50], y_test[:50]) + MSE(y_pred[150:], y_test[150:]))/2)\n",
    "    mse_dnn_5.append(MSE( y_pred, y_test))\n",
    "    mean_pred_dnn.append(y_pred)\n",
    "mean_pred_5 = np.array(mean_pred).mean(axis=0)\n",
    "mean_pred_ext_5 = np.array(mean_pred_ext).mean(axis=0)\n",
    "mean_pred_dnn_5 = np.array(mean_pred_dnn).mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a391c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f83531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat with training airfoil 5 (no simplified PBM input) replaced by training airfoil 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7994167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create alternative training set\n",
    "\n",
    "train_airfoils = [6, 13, 21, 25]\n",
    "validation_airfoils = [9]\n",
    "test_airfoils = [17]\n",
    "# dataset shapes:\n",
    "# x_train [samples, [x_coords,y_coords]]\n",
    "# x_train_phys [samples, alpha & cl_approx_exp & cl_approx_exp ]\n",
    "# y_train [samples, cl & cd]\n",
    "\n",
    "\n",
    "def process_data(airfoils):\n",
    "    x = []\n",
    "    x_phys_ext = []\n",
    "    x_phys = []\n",
    "    y = []\n",
    "    for airfoil in airfoils:\n",
    "        for i in range(len(data[airfoil][\"alpha\"])):\n",
    "            x.append(np.reshape(data[airfoil][\"coords_reduced\"],-1))\n",
    "            x_phys_ext.append([data[airfoil][\"alpha\"][i],data[airfoil][\"Cl_approx_exp\"][i],data[airfoil][\"Cd_approx_exp\"][i]])\n",
    "            x_phys.append([data[airfoil][\"alpha\"][i],data[airfoil][\"Cl_approx\"][i],data[airfoil][\"Cd_approx\"][i]])\n",
    "            y.append([data[airfoil][\"Cl_target\"][i], data[airfoil][\"Cd_target\"][i]])\n",
    "    x = np.array(x )\n",
    "    x_phys_ext = np.array(x_phys_ext)\n",
    "    x_phys = np.array(x_phys)\n",
    "    y = np.array(y)\n",
    "    return x, x_phys_ext, x_phys, y\n",
    "    \n",
    "    \n",
    "x_train, x_train_phys_ext, x_train_phys, y_train = process_data(train_airfoils)\n",
    "x_val, x_val_phys_ext, x_val_phys, y_val = process_data(validation_airfoils)\n",
    "x_test, x_test_phys_ext, x_test_phys, y_test = process_data(test_airfoils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "dac8db49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN  0 , Epochs 48 , loss 0.015738071873784065 , val_loss 0.01792730763554573\n",
      "NN  1 , Epochs 73 , loss 0.008283112198114395 , val_loss 0.01176405418664217\n",
      "NN  2 , Epochs 75 , loss 0.013804882764816284 , val_loss 0.015070997178554535\n",
      "NN  3 , Epochs 45 , loss 0.0230936910957098 , val_loss 0.025332069024443626\n",
      "NN  4 , Epochs 53 , loss 0.012182355858385563 , val_loss 0.01656709983944893\n",
      "NN  5 , Epochs 38 , loss 0.012372604571282864 , val_loss 0.016915082931518555\n",
      "NN  6 , Epochs 59 , loss 0.009333360940217972 , val_loss 0.013497688807547092\n",
      "NN  7 , Epochs 56 , loss 0.008204239420592785 , val_loss 0.012401836924254894\n",
      "NN  8 , Epochs 43 , loss 0.01958627998828888 , val_loss 0.022185098379850388\n",
      "NN  9 , Epochs 100 , loss 0.019025394693017006 , val_loss 0.02218046598136425\n",
      "NN  0 , Epochs 66 , loss 0.0056801591999828815 , val_loss 0.006791104096919298\n",
      "NN  1 , Epochs 40 , loss 0.0063677276484668255 , val_loss 0.007712156046181917\n",
      "NN  2 , Epochs 30 , loss 0.003738269442692399 , val_loss 0.0038976261857897043\n",
      "NN  3 , Epochs 43 , loss 0.005023878999054432 , val_loss 0.005294674541801214\n",
      "NN  4 , Epochs 37 , loss 0.004100590478628874 , val_loss 0.004029570147395134\n",
      "NN  5 , Epochs 43 , loss 0.007051375694572926 , val_loss 0.007463089190423489\n",
      "NN  6 , Epochs 46 , loss 0.0066727809607982635 , val_loss 0.007613157853484154\n",
      "NN  7 , Epochs 40 , loss 0.005157410632818937 , val_loss 0.005391055252403021\n",
      "NN  8 , Epochs 32 , loss 0.0041114152409136295 , val_loss 0.0035589265171438456\n",
      "NN  9 , Epochs 37 , loss 0.0037117667961865664 , val_loss 0.0033794594928622246\n",
      "NN  0 , Epochs 52 , loss 0.024124683812260628 , val_loss 0.025549644604325294\n",
      "NN  1 , Epochs 21 , loss 0.2237120270729065 , val_loss 0.23259136080741882\n",
      "NN  2 , Epochs 40 , loss 0.026663534343242645 , val_loss 0.02658732980489731\n",
      "NN  3 , Epochs 46 , loss 0.014848541468381882 , val_loss 0.016116004437208176\n",
      "NN  4 , Epochs 60 , loss 0.02092774584889412 , val_loss 0.023562999442219734\n",
      "NN  5 , Epochs 36 , loss 0.016232645139098167 , val_loss 0.018449895083904266\n",
      "NN  6 , Epochs 31 , loss 0.011015201918780804 , val_loss 0.014123771339654922\n",
      "NN  7 , Epochs 23 , loss 0.15196196734905243 , val_loss 0.15058712661266327\n",
      "NN  8 , Epochs 46 , loss 0.0530075840651989 , val_loss 0.05502820014953613\n",
      "NN  9 , Epochs 35 , loss 0.05313226208090782 , val_loss 0.05346599593758583\n"
     ]
    }
   ],
   "source": [
    "# create pgnn ensemble with extrapolated_data\n",
    "\n",
    "nns = 10\n",
    "\n",
    "if 1:\n",
    "    pgnns, pgnn_hists = build_ensemble(            \n",
    "            nns = nns,\n",
    "            mode = \"PGNN_3\", \n",
    "            x_train = x_train,\n",
    "            x_train_phys = x_train_phys,\n",
    "            y_train = y_train,\n",
    "            x_val = x_val,\n",
    "            x_val_phys = x_val_phys,\n",
    "            y_val = y_val,\n",
    "            verbose = 1)\n",
    "\n",
    "if 1:\n",
    "    pgnns_exp, pgnn_exp_hists = build_ensemble(            \n",
    "            nns =nns,\n",
    "            mode = \"PGNN_4\", \n",
    "            x_train = x_train,\n",
    "            x_train_phys = x_train_phys_ext,\n",
    "            y_train = y_train,\n",
    "            x_val = x_val,\n",
    "            x_val_phys = x_val_phys_ext,\n",
    "            y_val = y_val,\n",
    "            verbose = 1)\n",
    "\n",
    "dnn, dnn_hists = build_ensemble(            \n",
    "            nns = nns,\n",
    "            mode = \"DDNN\", \n",
    "            x_train = x_train,\n",
    "            x_train_phys = x_train_phys[:,0],\n",
    "            y_train = y_train,\n",
    "            x_val = x_val,\n",
    "            x_val_phys = x_val_phys[:,0],\n",
    "            y_val = y_val,\n",
    "            verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7b19d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "\n",
    "def MSE(x,y):\n",
    "    x = np.reshape(np.array(x),-1)\n",
    "    y = np.reshape(np.array(y),-1)\n",
    "    z = np.mean((x-y)**2)\n",
    "    return z\n",
    "\n",
    "mean_pred=[]\n",
    "mse_6 = []\n",
    "for model in pgnns:\n",
    "    y_pred = model.predict( \n",
    "        x = [x_test,x_test_phys],verbose=0\n",
    "    )\n",
    "    \n",
    "    #mse_6.append((MSE( y_pred[:50], y_test[:50]) + MSE(y_pred[150:], y_test[150:]))/2)\n",
    "    mse_6.append(MSE( y_pred, y_test))\n",
    "    mean_pred.append(y_pred)\n",
    "\n",
    "mean_pred_ext = []\n",
    "mse_ext_6=[]\n",
    "for model in pgnns_exp:\n",
    "    y_pred = model.predict( \n",
    "        x = [x_test,x_test_phys_ext],verbose=0\n",
    "    )\n",
    "    \n",
    "    #mse_ext_6.append((MSE( y_pred[:50], y_test[:50]) + MSE(y_pred[150:], y_test[150:]))/2)\n",
    "    mse_ext_6.append(MSE( y_pred, y_test))\n",
    "    mean_pred_ext.append(y_pred)\n",
    "\n",
    "mean_pred_dnn = []\n",
    "mse_dnn_6 = []\n",
    "for model in dnn:\n",
    "    y_pred = model.predict( \n",
    "        x = [x_test,x_test_phys[:,0]], verbose=0\n",
    "    )\n",
    "    #mse_dnn_6.append((MSE( y_pred[:50], y_test[:50]) + MSE(y_pred[150:], y_test[150:]))/2)\n",
    "    mse_dnn_6.append(MSE( y_pred, y_test))\n",
    "    mean_pred_dnn.append(y_pred)\n",
    "    \n",
    "\n",
    "mean_pred_xfoil = np.array(MSE( x_test_phys[:,1:], y_test))\n",
    "mean_pred_xfoil_ext = np.array(MSE( x_test_phys_ext[:,1:], y_test))\n",
    "    \n",
    "mean_pred_6 = np.array(mean_pred).mean(axis=0)\n",
    "mean_pred_ext_6 = np.array(mean_pred_ext).mean(axis=0)\n",
    "mean_pred_dnn_6 = np.array(mean_pred_dnn).mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b14f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "21232976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plot data\n",
    "\n",
    "mse = {\n",
    "    \"mse_5\":mse_5,\n",
    "    \"mse_6\":mse_6,\n",
    "    \"mse_ext_5\":mse_ext_5,\n",
    "    \"mse_ext_6\":mse_ext_6,\n",
    "    \"mse_dnn_5\":mse_dnn_5,\n",
    "    \"mse_dnn_6\":mse_dnn_6,\n",
    "    \"mse_xfoil\":mean_pred_xfoil,\n",
    "    \"mse_xfoil_ext\":mean_pred_xfoil_ext,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8abe7aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse[\"mse_xfoil\"]=mean_pred_xfoil\n",
    "mse[\"mse_xfoil_ext\"]=mean_pred_xfoil_ext\n",
    "#with open(\"Plot_data/purified.pkl\", \"wb\") as f:\n",
    "#    pickle.dump(mse,f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba073d1c",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67b95fcf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Plot_data/purified.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21152/4014171103.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Plot_data/purified.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m font = {\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Plot_data/purified.pkl'"
     ]
    }
   ],
   "source": [
    "with open(\"Plot_data/purified.pkl\", \"rb\") as f:\n",
    "    mse = pickle.load(f)\n",
    "    \n",
    "import matplotlib\n",
    "font = {\n",
    "        'size'   : 15}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,6))\n",
    "plt.yscale(\"log\")\n",
    "plt.boxplot(mse[\"mse_5\"],positions = [0], labels=[\"Zero t5\"])\n",
    "plt.boxplot(mse[\"mse_6\"],positions = [0.4], labels=[\"Zero t6\"])\n",
    "plt.boxplot(mse[\"mse_ext_5\"],positions = [1.2], labels=[\"Viterna t5\"])\n",
    "plt.boxplot(mse[\"mse_ext_6\"],positions = [1.6], labels=[\"Viterna t6\"])\n",
    "plt.boxplot(mse[\"mse_dnn_5\"],positions = [2.4], labels=[\"DNN t5\"])\n",
    "plt.boxplot(mse[\"mse_dnn_6\"],positions = [2.8], labels=[\"DNN t6\"])\n",
    "\n",
    "plt.plot([-0.2,3],[mse[\"mse_xfoil\"],mse[\"mse_xfoil\"]],label=\"Simplified PBM\", color=\"#1f77b4\")\n",
    "plt.plot([-0.2,3],[mse[\"mse_xfoil_ext\"],mse[\"mse_xfoil_ext\"]],label=\"Simplified PBM with extrapolation\", color=\"#1f77b4\", linestyle = \"--\")\n",
    "plt.legend(prop={'size':14}, loc = \"upper left\", bbox_to_anchor=(0,0.9))\n",
    "#plt.legend(prop={'size':14}, loc = \"upper left\", bbox_to_anchor=(0,1))\n",
    "#plt.ylim(0.0018,0.99)\n",
    "#plt.ylim(0.0015,1.2)\n",
    "#plt.xlim(-0.2,3)\n",
    "\n",
    "labels = [\"A5\", \"A6\", \"A5\", \"A6\", \"A5\", \"A6\"]\n",
    "group = [\"\\nPGNN with\\nsimplified\\nPBM\", \"\\nPGNN with\\nsimplified PBM\\nand extrapolation\", \"\\nDDNN\"]\n",
    "ticks= ax.get_xticks()\n",
    "ax.set_xticks(ticks,  minor=True)\n",
    "ax.set_xticklabels(labels, minor=True)\n",
    "ax.set_xticks([0.2,1.4,2.6], minor=False)\n",
    "ax.set_xticklabels(group, minor=False)\n",
    "plt.ylabel(\"Mean squared error\", size=16)\n",
    "plt.xlabel(\"\\nModel configuration\", size=16)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.tick_params(axis='x', which='major', bottom=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"purified.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b55594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ca2e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8edd50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "310493f3",
   "metadata": {},
   "source": [
    "# Test which injection layer is best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3ed0ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(x,y):\n",
    "    x = np.reshape(np.array(x),-1)\n",
    "    y = np.reshape(np.array(y),-1)\n",
    "    z = np.mean((x-y)**2)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8091db11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN  0 , Epochs 146 , loss 0.014099065214395523 , val_loss 0.013796405866742134\n",
      "NN  1 , Epochs 32 , loss 0.051910728216171265 , val_loss 0.05133821442723274\n",
      "NN  2 , Epochs 56 , loss 0.012860295362770557 , val_loss 0.017096925526857376\n",
      "NN  3 , Epochs 29 , loss 0.3254958391189575 , val_loss 0.35588863492012024\n",
      "NN  4 , Epochs 40 , loss 0.06807991862297058 , val_loss 0.0647411122918129\n",
      "NN  5 , Epochs 41 , loss 0.05170825123786926 , val_loss 0.05093712732195854\n",
      "NN  6 , Epochs 93 , loss 0.03945550322532654 , val_loss 0.03646839037537575\n",
      "NN  7 , Epochs 52 , loss 0.04248170927166939 , val_loss 0.04519762843847275\n",
      "NN  8 , Epochs 35 , loss 0.06062361225485802 , val_loss 0.06689499318599701\n",
      "NN  9 , Epochs 42 , loss 0.061278052628040314 , val_loss 0.06168333441019058\n",
      "NN  0 , Epochs 56 , loss 0.047491248697042465 , val_loss 0.048520464450120926\n",
      "NN  1 , Epochs 30 , loss 0.1282922774553299 , val_loss 0.11211810261011124\n",
      "NN  2 , Epochs 52 , loss 0.008868257515132427 , val_loss 0.009737835265696049\n",
      "NN  3 , Epochs 72 , loss 0.02917398139834404 , val_loss 0.028082065284252167\n",
      "NN  4 , Epochs 53 , loss 0.01093289628624916 , val_loss 0.012372276745736599\n",
      "NN  5 , Epochs 78 , loss 0.00772971473634243 , val_loss 0.008688423782587051\n",
      "NN  6 , Epochs 26 , loss 0.12712717056274414 , val_loss 0.11267396807670593\n",
      "NN  7 , Epochs 47 , loss 0.010844561271369457 , val_loss 0.013983633369207382\n",
      "NN  8 , Epochs 106 , loss 0.029824361205101013 , val_loss 0.029574165120720863\n",
      "NN  9 , Epochs 74 , loss 0.024797022342681885 , val_loss 0.0254016425460577\n",
      "NN  0 , Epochs 48 , loss 0.008232261054217815 , val_loss 0.010870436206459999\n",
      "NN  1 , Epochs 37 , loss 0.007544759660959244 , val_loss 0.007699722424149513\n",
      "NN  2 , Epochs 56 , loss 0.0065873353742063046 , val_loss 0.00620214082300663\n",
      "NN  3 , Epochs 63 , loss 0.009435185231268406 , val_loss 0.01011670008301735\n",
      "NN  4 , Epochs 69 , loss 0.008665170520544052 , val_loss 0.008735368959605694\n",
      "NN  5 , Epochs 47 , loss 0.00737431924790144 , val_loss 0.006691036280244589\n",
      "NN  6 , Epochs 86 , loss 0.011781654320657253 , val_loss 0.013363075442612171\n",
      "NN  7 , Epochs 47 , loss 0.008008154109120369 , val_loss 0.0075766597874462605\n",
      "NN  8 , Epochs 57 , loss 0.00602888036519289 , val_loss 0.007722495123744011\n",
      "NN  9 , Epochs 90 , loss 0.005915921181440353 , val_loss 0.0057962979190051556\n",
      "NN  0 , Epochs 52 , loss 0.0037167363334447145 , val_loss 0.0037821070291101933\n",
      "NN  1 , Epochs 37 , loss 0.005656799767166376 , val_loss 0.006103415973484516\n",
      "NN  2 , Epochs 46 , loss 0.01125576626509428 , val_loss 0.01161056850105524\n",
      "NN  3 , Epochs 47 , loss 0.004977166187018156 , val_loss 0.004984515719115734\n",
      "NN  4 , Epochs 33 , loss 0.008417975157499313 , val_loss 0.0081026004627347\n",
      "NN  5 , Epochs 46 , loss 0.00464256014674902 , val_loss 0.0037504383362829685\n",
      "NN  6 , Epochs 28 , loss 0.008512388914823532 , val_loss 0.0092881815508008\n",
      "NN  7 , Epochs 40 , loss 0.003331821644678712 , val_loss 0.0029856853652745485\n",
      "NN  8 , Epochs 47 , loss 0.006193977780640125 , val_loss 0.006457209587097168\n",
      "NN  9 , Epochs 34 , loss 0.008586238138377666 , val_loss 0.009296457283198833\n",
      "NN  0 , Epochs 39 , loss 0.006817868445068598 , val_loss 0.0071941884234547615\n",
      "NN  1 , Epochs 35 , loss 0.006636669859290123 , val_loss 0.006971975788474083\n",
      "NN  2 , Epochs 31 , loss 0.005319767631590366 , val_loss 0.004836163017898798\n",
      "NN  3 , Epochs 39 , loss 0.005589234177023172 , val_loss 0.005499806255102158\n",
      "NN  4 , Epochs 41 , loss 0.007148104254156351 , val_loss 0.00728607876226306\n",
      "NN  5 , Epochs 39 , loss 0.00812247022986412 , val_loss 0.008325488306581974\n",
      "NN  6 , Epochs 37 , loss 0.0051031350158154964 , val_loss 0.004784317221492529\n",
      "NN  7 , Epochs 50 , loss 0.004857414402067661 , val_loss 0.005041145719587803\n",
      "NN  8 , Epochs 30 , loss 0.004702635575085878 , val_loss 0.0048806448467075825\n",
      "NN  9 , Epochs 20 , loss 0.011556703597307205 , val_loss 0.011626026593148708\n",
      "NN  0 , Epochs 26 , loss 0.008392861112952232 , val_loss 0.00732302013784647\n",
      "NN  1 , Epochs 39 , loss 0.007150769699364901 , val_loss 0.006430520210415125\n",
      "NN  2 , Epochs 30 , loss 0.006409522145986557 , val_loss 0.005745419766753912\n",
      "NN  3 , Epochs 37 , loss 0.007551122456789017 , val_loss 0.006581466179341078\n",
      "NN  4 , Epochs 28 , loss 0.009401383809745312 , val_loss 0.008035290986299515\n",
      "NN  5 , Epochs 34 , loss 0.008108858950436115 , val_loss 0.007214359473437071\n",
      "NN  6 , Epochs 29 , loss 0.008981718681752682 , val_loss 0.008261973038315773\n",
      "NN  7 , Epochs 34 , loss 0.01045302301645279 , val_loss 0.009352548979222775\n",
      "NN  8 , Epochs 24 , loss 0.007509793154895306 , val_loss 0.0066801998764276505\n",
      "NN  9 , Epochs 28 , loss 0.00768241286277771 , val_loss 0.007323761470615864\n"
     ]
    }
   ],
   "source": [
    "# function for creating an ensemble\n",
    "nns = 10\n",
    "mmodels = []\n",
    "hiists=[]\n",
    "\n",
    "for i in range(1,7):\n",
    "    models, hists = build_ensemble(\n",
    "                nns, \n",
    "                mode = \"PGNN_\"+str(i), \n",
    "                x_train=x_train,\n",
    "                x_train_phys=x_train_phys_ext,\n",
    "                y_train=y_train,\n",
    "                x_val=x_val,\n",
    "                x_val_phys = x_val_phys_ext,\n",
    "                y_val = y_val,\n",
    "                verbose = 1\n",
    "    )\n",
    "    mmodels.append(models)\n",
    "    hiists.append(hists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "772ed2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "mse = []\n",
    "\n",
    "for i in range(len(mmodels)):\n",
    "    mse_2=[]\n",
    "    for model in mmodels[i]:\n",
    "        y_pred = model.predict( \n",
    "            x = [x_test,x_test_phys_ext],verbose=0\n",
    "        )\n",
    "\n",
    "        #mse_ext_6.append((MSE( y_pred[:50], y_test[:50]) + MSE(y_pred[150:], y_test[150:]))/2)\n",
    "        mse_2.append(MSE( y_pred, y_test))\n",
    "    mse.append(mse_2)\n",
    "with open(\"Plot_data/injection_layer_extended.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mse,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cae14434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98fe53b4d06545bd8f01c84704778c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"Plot_data/injection_layer_extended.pkl\", \"rb\") as f:\n",
    "    mse = pickle.load(f)\n",
    "    \n",
    "    \n",
    "import matplotlib\n",
    "font = {\n",
    "        'size'   : 16}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "plt.figure()\n",
    "plt.yscale(\"log\")\n",
    "for i in range(len(mse)):\n",
    "    plt.boxplot(mse[i],positions=[i])\n",
    "plt.ylabel(\"Mean squared error\")\n",
    "plt.xticks([0,1,2,3,4,5], [\"L1\",\"L2\",\"L3\",\"L4\",\"L5\",\"L6\"])\n",
    "plt.xlabel(\"Injection layer\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"injection_layer_extended.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5caf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
